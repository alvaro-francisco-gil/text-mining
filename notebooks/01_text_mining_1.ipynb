{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.2.0+cpu\n",
      "CUDA available: False\n",
      "CUDA device name: No CUDA device detected\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.2.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import UDPOS, CoNLL2000Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train, validation, and test datasets\n",
    "train_iter, valid_iter, test_iter = UDPOS(root='.data', split=('train', 'valid', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few items in the training set\n",
    "for i, item in enumerate(train_iter):\n",
    "    print(item)\n",
    "    if i == 0:  # Print first 5 items\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ShardingFilterIterDataPipe"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at QCRI/bert-base-multilingual-cased-pos-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'DT', 'score': 0.9997243, 'index': 1, 'word': 'A', 'start': 0, 'end': 1}, {'entity': 'NN', 'score': 0.9997472, 'index': 2, 'word': 'test', 'start': 2, 'end': 6}, {'entity': 'NN', 'score': 0.99973196, 'index': 3, 'word': 'example', 'start': 7, 'end': 14}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline\n",
    "\n",
    "model_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "pipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "outputs = pipeline(\"A test example\")\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 46\n"
     ]
    }
   ],
   "source": [
    "num_labels = model.config.num_labels\n",
    "print(f\"Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 0, Tag: O\n",
      "ID: 1, Tag: ``\n",
      "ID: 2, Tag: ,\n",
      "ID: 3, Tag: :\n",
      "ID: 4, Tag: .\n",
      "ID: 5, Tag: ''\n",
      "ID: 6, Tag: $\n",
      "ID: 7, Tag: #\n",
      "ID: 8, Tag: CC\n",
      "ID: 9, Tag: CD\n",
      "ID: 10, Tag: DT\n",
      "ID: 11, Tag: EX\n",
      "ID: 12, Tag: FW\n",
      "ID: 13, Tag: IN\n",
      "ID: 14, Tag: JJ\n",
      "ID: 15, Tag: JJR\n",
      "ID: 16, Tag: JJS\n",
      "ID: 17, Tag: -LRB-\n",
      "ID: 18, Tag: LS\n",
      "ID: 19, Tag: MD\n",
      "ID: 20, Tag: NN\n",
      "ID: 21, Tag: NNP\n",
      "ID: 22, Tag: NNPS\n",
      "ID: 23, Tag: NNS\n",
      "ID: 24, Tag: PDT\n",
      "ID: 25, Tag: POS\n",
      "ID: 26, Tag: PRP\n",
      "ID: 27, Tag: PRP$\n",
      "ID: 28, Tag: RB\n",
      "ID: 29, Tag: RBR\n",
      "ID: 30, Tag: RBS\n",
      "ID: 31, Tag: RP\n",
      "ID: 32, Tag: -RRB-\n",
      "ID: 33, Tag: SYM\n",
      "ID: 34, Tag: TO\n",
      "ID: 35, Tag: UH\n",
      "ID: 36, Tag: VB\n",
      "ID: 37, Tag: VBD\n",
      "ID: 38, Tag: VBG\n",
      "ID: 39, Tag: VBN\n",
      "ID: 40, Tag: VBP\n",
      "ID: 41, Tag: VBZ\n",
      "ID: 42, Tag: WDT\n",
      "ID: 43, Tag: WP\n",
      "ID: 44, Tag: WP$\n",
      "ID: 45, Tag: WRB\n"
     ]
    }
   ],
   "source": [
    "for id, label in label_map.items():\n",
    "    print(f\"ID: {id}, Tag: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train, validation, and test datasets\n",
    "train_iter, test_iter = CoNLL2000Chunking(root='.data', split=('train', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'portalocker' has no attribute 'LockFlags'\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tags\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Extract unique chunk tags from the training data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m train_tags \u001b[38;5;241m=\u001b[39m \u001b[43mextract_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnique Chunk Tags:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_tags)\n",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m, in \u001b[0;36mextract_tags\u001b[1;34m(data_iter)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_tags\u001b[39m(data_iter):\n\u001b[0;32m      3\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\sharding.py:76\u001b[0m, in \u001b[0;36mShardingFilterIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_of_instances\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_id\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combinatorics.py:127\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe:\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchtext\\data\\datasets_utils.py:300\u001b[0m, in \u001b[0;36m_ParseIOBData.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     columns \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\plain_text_reader.py:134\u001b[0m, in \u001b[0;36mLineReaderIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[Str_Or_Bytes, Tuple[\u001b[38;5;28mstr\u001b[39m, Str_Or_Bytes]]]:\n\u001b[1;32m--> 134\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip_newline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\fileopener.py:66\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:215\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[1;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mode\n\u001b[1;32m--> 215\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpathnames\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mraise\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mTypeError\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExpected string type for pathname, but got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:55\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipes:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m dp\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:55\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipes:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m dp\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:455\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;66;03m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;66;03m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrec_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_cell_dp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_file_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_filepath_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m---> 53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:124\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m--> 124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:124\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m--> 124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\decompressor.py:97\u001b[0m, in \u001b[0;36mDecompressorIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Tuple[\u001b[38;5;28mstr\u001b[39m, StreamWrapper]]:\n\u001b[1;32m---> 97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_compression_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\fileopener.py:66\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:215\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[1;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mode\n\u001b[1;32m--> 215\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpathnames\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mraise\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;167;43;01mTypeError\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExpected string type for pathname, but got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpathname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:230\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_caching_flag:\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_datapipe\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;66;03m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease call `end_caching()` before iteration.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:375\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremember_elements\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:152\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:140\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return next with logic related to iterator validity, profiler, and incrementation of samples yielded.\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m _check_iterator_valid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator_id)\n\u001b[1;32m--> 140\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_and_has_next_method:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:468\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[1;34m(self, instance_id)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_child_stop[instance_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:437\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[1;34m(self, instance_id)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapipe_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 437\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datapipe_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier_fn(value)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_none:\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:55\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipes:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m dp\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:55\u001b[0m, in \u001b[0;36mConcaterIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipes:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m dp\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:455\u001b[0m, in \u001b[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[38;5;66;03m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001b[39;00m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;66;03m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrec_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_cell_dp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_last\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_file_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_filepath_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\saver.py:53\u001b[0m, in \u001b[0;36mSaverIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m---> 53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\hashchecker.py:67\u001b[0m, in \u001b[0;36mHashCheckerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Tuple[\u001b[38;5;28mstr\u001b[39m, StreamWrapper]]:\n\u001b[1;32m---> 67\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msha256\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhash_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhashlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msha256\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:124\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m--> 124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:124\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m--> 124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\load\\online.py:91\u001b[0m, in \u001b[0;36mHTTPReaderIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Tuple[\u001b[38;5;28mstr\u001b[39m, StreamWrapper]]:\n\u001b[1;32m---> 91\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_response_from_http\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:230\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_caching_flag:\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_datapipe\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;66;03m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001b[39;00m\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease call `end_caching()` before iteration.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:181\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     datapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:375\u001b[0m, in \u001b[0;36m_MemoryCellIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 375\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_datapipe\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_pos\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremember_elements\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:152\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:140\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return next with logic related to iterator validity, profiler, and incrementation of samples yielded.\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m _check_iterator_valid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator_id)\n\u001b[1;32m--> 140\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_and_has_next_method:\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapipe\u001b[38;5;241m.\u001b[39m_number_of_samples_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:468\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001b[1;34m(self, instance_id)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_child_stop[instance_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:438\u001b[0m, in \u001b[0;36m_DemultiplexerIterDataPipe._find_next\u001b[1;34m(self, instance_id)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_datapipe_iterator has not been set, likely because this private method is called directly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout invoking get_next_element_by_instance() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datapipe_iterator)\n\u001b[1;32m--> 438\u001b[0m classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_none:\n\u001b[0;32m    440\u001b[0m     StreamWrapper\u001b[38;5;241m.\u001b[39mclose_streams(value)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\.virtualenvs\\text_mining-F4nBXGac\\Lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:263\u001b[0m, in \u001b[0;36mOnDiskCacheHolderIterDataPipe._cache_check_fn\u001b[1;34m(data, filepath_fn, hash_dict, hash_type, extra_check_fn, cache_uuid)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dirname):\n\u001b[0;32m    261\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(dirname)\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m portalocker\u001b[38;5;241m.\u001b[39mLock(promise_filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma+\u001b[39m\u001b[38;5;124m\"\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[43mportalocker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLockFlags\u001b[49m\u001b[38;5;241m.\u001b[39mEXCLUSIVE) \u001b[38;5;28;01mas\u001b[39;00m promise_fh:\n\u001b[0;32m    264\u001b[0m     promise_fh\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    265\u001b[0m     data \u001b[38;5;241m=\u001b[39m promise_fh\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'portalocker' has no attribute 'LockFlags'\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)"
     ]
    }
   ],
   "source": [
    "# Function to extract unique chunk tags\n",
    "def extract_tags(data_iter):\n",
    "    tags = set()\n",
    "    for sentence in data_iter:\n",
    "        for word, pos, chunk in sentence:\n",
    "            tags.add(chunk)\n",
    "    return tags\n",
    "\n",
    "# Extract unique chunk tags from the training data\n",
    "train_tags = extract_tags(train_iter)\n",
    "print(\"Unique Chunk Tags:\", train_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining-F4nBXGac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
