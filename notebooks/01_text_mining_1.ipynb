{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "server_ip = os.getenv('SERVER_IP')\n",
    "port = os.getenv('PORT')\n",
    "\n",
    "BASE_URL = f\"http://{server_ip}:{port}/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.2.0+cu121\n",
      "CUDA available: True\n",
      "CUDA device name: NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA device detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import UDPOS\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline\n",
    "import openai\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train, validation, and test datasets\n",
    "train_iter, valid_iter, test_iter = UDPOS(root='.data', split=('train', 'valid', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['What', 'if', 'Google', 'Morphed', 'Into', 'GoogleOS', '?'], ['PRON', 'SCONJ', 'PROPN', 'VERB', 'ADP', 'PROPN', 'PUNCT'], ['WP', 'IN', 'NNP', 'VBD', 'IN', 'NNP', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few items in the training set\n",
    "for i, item in enumerate(test_iter):\n",
    "    print(item)\n",
    "    if i == 0:  # Print first 5 items\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at QCRI/bert-base-multilingual-cased-pos-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Using /root/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Failed to load CUDA kernels. Mra requires custom CUDA kernels. Please verify that compatible versions of PyTorch and CUDA Toolkit are installed: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "pipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'DT', 'score': 0.9997243, 'index': 1, 'word': 'A', 'start': 0, 'end': 1}, {'entity': 'NN', 'score': 0.9997472, 'index': 2, 'word': 'test', 'start': 2, 'end': 6}, {'entity': 'NN', 'score': 0.99973196, 'index': 3, 'word': 'example', 'start': 7, 'end': 14}]\n"
     ]
    }
   ],
   "source": [
    "outputs = pipeline(\"A test example\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixtral 8x7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base URL to point to your running LM Studio server\n",
    "openai.api_base = BASE_URL\n",
    "openai.api_key = \"dummy-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning!\\n\\nI am your virtual assistant for today. How can I assist'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    model=\"mixtral-8x7b-instruct-v0.1\",\n",
    "    prompt=\"Answer this: <Hello, good morning!>\",\n",
    "    max_tokens=20\n",
    ")\n",
    "response[\"choices\"][0][\"text\"].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    }
   ],
   "source": [
    "# Extract sentences and ground truth POS tags from test_iter\n",
    "sentences = [item[0] for item in test_iter]  # Extract tokenized sentences\n",
    "ground_truth_tags = [item[1] for item in test_iter]  # Extract ground truth POS tags\n",
    "\n",
    "example_sentence = sentences[0]\n",
    "example_true_tag = ground_truth_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_true_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map Penn Treebank tags to UDPOS tags\n",
    "penn_to_udpos = {\n",
    "    'O': 'X',\n",
    "    '``': 'PUNCT',\n",
    "    ',': 'PUNCT',\n",
    "    ':': 'PUNCT',\n",
    "    '.': 'PUNCT',\n",
    "    \"''\": 'PUNCT',\n",
    "    '$': 'SYM',\n",
    "    '#': 'SYM',\n",
    "    'CC': 'CCONJ',\n",
    "    'CD': 'NUM',\n",
    "    'DT': 'DET',\n",
    "    'EX': 'PRON',\n",
    "    'FW': 'X',\n",
    "    'IN': 'ADP',\n",
    "    'JJ': 'ADJ',\n",
    "    'JJR': 'ADJ',\n",
    "    'JJS': 'ADJ',\n",
    "    '-LRB-': 'PUNCT',\n",
    "    'LS': 'X',\n",
    "    'MD': 'AUX',\n",
    "    'NN': 'NOUN',\n",
    "    'NNP': 'PROPN',\n",
    "    'NNPS': 'PROPN',\n",
    "    'NNS': 'NOUN',\n",
    "    'PDT': 'DET',\n",
    "    'POS': 'PART',\n",
    "    'PRP': 'PRON',\n",
    "    'PRP$': 'PRON',\n",
    "    'RB': 'ADV',\n",
    "    'RBR': 'ADV',\n",
    "    'RBS': 'ADV',\n",
    "    'RP': 'PART',\n",
    "    '-RRB-': 'PUNCT',\n",
    "    'SYM': 'SYM',\n",
    "    'TO': 'PART',\n",
    "    'UH': 'INTJ',\n",
    "    'VB': 'VERB',\n",
    "    'VBD': 'VERB',\n",
    "    'VBG': 'VERB',\n",
    "    'VBN': 'VERB',\n",
    "    'VBP': 'VERB',\n",
    "    'VBZ': 'VERB',\n",
    "    'WDT': 'DET',\n",
    "    'WP': 'PRON',\n",
    "    'WP$': 'PRON',\n",
    "    'WRB' : 'ADV'\n",
    "}\n",
    "\n",
    "def convert_penn_to_udpos(predictions):\n",
    "    \"\"\"\n",
    "    Convert a list of predictions with Penn Treebank tags to UDPOS tags.\n",
    "\n",
    "    :param predictions: List of dictionaries with an `entity` key for Penn Treebank tag.\n",
    "                        Example: [{'entity':'DT', ...}, ...]\n",
    "    \n",
    "    :return: List of dictionaries with `entity` key converted to UDPOS tag.\n",
    "             Example: [{'entity':'DET', ...}, ...]\n",
    "    \"\"\"\n",
    "    # Ensure predictions is a list of dictionaries\n",
    "    if isinstance(predictions, dict):\n",
    "        predictions = [predictions]\n",
    "    elif isinstance(predictions[0], list):\n",
    "        predictions = [item for sublist in predictions for item in sublist]\n",
    "\n",
    "    for prediction in predictions:\n",
    "        penn_tag = prediction.get('entity')  # Safely get 'entity' key\n",
    "        if penn_tag is not None:\n",
    "            # Map Penn Treebank tag to UDPOS tag, defaulting to `X`\n",
    "            prediction['entity'] = penn_to_udpos.get(penn_tag, \"X\")\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = pipeline(example_sentence)\n",
    "udpos_outputs = convert_penn_to_udpos(outputs)\n",
    "bert_prediction = [item['entity'] for item in udpos_outputs]\n",
    "print(bert_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTJ', 'CCONJ', 'PROPN', 'VERB', 'ADP', 'PROPN', 'PUNCT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tag_sentence(sentence, track_responses=None):\n",
    "    \"\"\"\n",
    "    Perform POS tagging on a sentence and keep track of raw and parsed responses.\n",
    "\n",
    "    Parameters:\n",
    "      - sentence (str): The input sentence to perform POS tagging on.\n",
    "      - track_responses (list, optional): A list to store raw and parsed responses for tracking.\n",
    "\n",
    "    Returns:\n",
    "      - dict: Parsed JSON response or an error message if parsing fails.\n",
    "    \"\"\"\n",
    "    # Define the POS tags with their descriptions\n",
    "    pos_labels = {\n",
    "        \"ADJ\": \"adjective\",\n",
    "        \"ADP\": \"adposition\",\n",
    "        \"ADV\": \"adverb\",\n",
    "        \"AUX\": \"auxiliary\",\n",
    "        \"CCONJ\": \"coordinating conjunction\",\n",
    "        \"DET\": \"determiner\",\n",
    "        \"INTJ\": \"interjection\",\n",
    "        \"NOUN\": \"noun\",\n",
    "        \"NUM\": \"numeral\",\n",
    "        \"PART\": \"particle\",\n",
    "        \"PRON\": \"pronoun\",\n",
    "        \"PROPN\": \"proper noun\",\n",
    "        \"PUNCT\": \"punctuation\",\n",
    "        \"SCONJ\": \"subordinating conjunction\",\n",
    "        \"SYM\": \"symbol\",\n",
    "        \"VERB\": \"verb\",\n",
    "        \"X\": \"other\"\n",
    "    }\n",
    "\n",
    "    # Construct the prompt with instructions for POS tagging\n",
    "    prompt = (\n",
    "        f\"Perform POS tagging on the following sentence using these labels: {pos_labels}. \"\n",
    "        f\"Output each word with its tag in JSON format.\\n\\nSentence: \\\"{sentence}\\\"\"\n",
    "    )\n",
    "\n",
    "    # Send request to the model\n",
    "    response = openai.Completion.create(\n",
    "        model=\"mixtral-8x7b-instruct-v0.1\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=-1\n",
    "    )\n",
    "\n",
    "    # Extract text from response\n",
    "    raw_output = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    # Preprocess and clean the raw output\n",
    "    cleaned_output = preprocess_raw_output(raw_output)\n",
    "\n",
    "    # Attempt to parse the cleaned output as JSON\n",
    "    try:\n",
    "        parsed_json = json.loads(cleaned_output)\n",
    "    except json.JSONDecodeError:\n",
    "        parsed_json = {\"error\": \"Response could not be parsed as JSON\", \"raw_output\": cleaned_output}\n",
    "\n",
    "    # Track responses if a tracking list is provided\n",
    "    if track_responses is not None:\n",
    "        track_responses.append({\"raw_response\": raw_output, \"parsed_json\": parsed_json})\n",
    "\n",
    "    return parsed_json\n",
    "\n",
    "\n",
    "def preprocess_raw_output(raw_output):\n",
    "    \"\"\"\n",
    "    Preprocess and clean the raw output to make it valid JSON.\n",
    "    \n",
    "    - Fix common issues like invalid JSON syntax.\n",
    "    \n",
    "    Parameters:\n",
    "      raw_output (str): The raw output from the model.\n",
    "      \n",
    "    Returns:\n",
    "      str: The cleaned output.\n",
    "    \"\"\"\n",
    "    # Replace invalid JSON entries (e.g., `{\".\", \".\"}` -> `{\".\": \".\"}`)\n",
    "    cleaned_output = raw_output.replace('{\".\", \".\"}', '{\".\": \".\"}')\n",
    "    \n",
    "    # Additional cleaning logic can go here if needed\n",
    "    return cleaned_output\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sentence = example_sentence\n",
    "responses_log = []\n",
    "\n",
    "pos_tags_json = pos_tag_sentence(sentence, track_responses=responses_log)\n",
    "mixtral_prediction = [item['tag'] for item in pos_tags_json]\n",
    "\n",
    "mixtral_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'if', 'Google', 'Morphed', 'Into', 'GoogleOS', '?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'SCONJ', 'PROPN', 'VERB', 'ADP', 'PROPN', 'PUNCT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example_true_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'ADP', 'PROPN', 'VERB', 'VERB', 'VERB', 'ADP', 'PROPN', 'PROPN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(bert_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INTJ', 'CCONJ', 'PROPN', 'VERB', 'ADP', 'PROPN', 'PUNCT']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mixtral_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
