{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import BisectingKMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import gensim.downloader as api\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = '/text-mining/data/02_text_representation/Corpus-representacion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files_to_dict(folder_path):\n",
    "    files_dict = {}\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    files_dict[file_path] = f.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read file {file_path}: {e}\")\n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = save_files_to_dict(data_folder_path)\n",
    "data = list(data_dict.values())\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.sys.ibm.pc.hardware', 'talk.politics.mideast', 'talk.politics.guns', 'sci.electronics', 'rec.autos', 'rec.sport.hockey', 'comp.sys.mac.hardware']\n"
     ]
    }
   ],
   "source": [
    "categories = [path.split('/')[-2] for path in data_dict.keys()]\n",
    "label_encoder = LabelEncoder()\n",
    "true_labels = label_encoder.fit_transform(categories)\n",
    "unique_categories = list(set(categories))\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_representations = np.load(\"../02_text_representation/02_text_representations_tf.npy\")\n",
    "tfidf_representations = np.load(\"../02_text_representation/02_text_representations_tfidf.npy\")\n",
    "word2vec_avg_representations = np.load(\"../02_text_representation/02_text_representations_word2vec_avg.npy\")\n",
    "word2vec_sum_representations = np.load(\"../02_text_representation/02_text_representations_word2vec_sum.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_statistics(data, categories, unique_categories):\n",
    "    \"\"\"\n",
    "    Analyze document statistics by category and create visualizations.\n",
    "\n",
    "    Args:\n",
    "        data: List of document texts\n",
    "        categories: List of category labels for each document\n",
    "        unique_categories: List of unique category names\n",
    "    \"\"\"\n",
    "    # Calculate word counts for each category\n",
    "    category_stats = {}\n",
    "\n",
    "    for i, category in enumerate(unique_categories):\n",
    "        # Get indices for this category\n",
    "        category_indices = [j for j, cat in enumerate(categories) if cat == category]\n",
    "\n",
    "        # Get documents for this category\n",
    "        category_docs = [data[j] for j in category_indices]\n",
    "\n",
    "        # Calculate word counts\n",
    "        word_counts = [len(doc.split()) for doc in category_docs]\n",
    "\n",
    "        # Store statistics\n",
    "        category_stats[category] = {\n",
    "            'doc_count': len(category_docs),\n",
    "            'word_count_mean': np.mean(word_counts) if word_counts else 0, # Handle empty categories\n",
    "            'word_count_std': np.std(word_counts) if word_counts else 0   # Handle empty categories\n",
    "        }\n",
    "\n",
    "    # Print statistics information\n",
    "    print(\"Document Statistics by Category:\")\n",
    "    for category, stats in category_stats.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(f\"  Number of documents: {stats['doc_count']}\")\n",
    "        print(f\"  Mean word count: {stats['word_count_mean']:.2f} words\")\n",
    "        print(f\"  Std word count: {stats['word_count_std']:.2f} words\")\n",
    "\n",
    "    # Create dataframe for plotting\n",
    "    word_count_df = pd.DataFrame({\n",
    "        'Category': list(category_stats.keys()),\n",
    "        'Mean Word Count': [stats['word_count_mean'] for stats in category_stats.values()],\n",
    "        'Std Word Count': [stats['word_count_std'] for stats in category_stats.values()]\n",
    "    })\n",
    "\n",
    "    # --- Plot for Number of Documents ---\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    doc_counts = [stats['doc_count'] for stats in category_stats.values()]\n",
    "    categories_for_plot = list(category_stats.keys())\n",
    "    ax_doc_count = sns.barplot(x=categories_for_plot, y=doc_counts)\n",
    "\n",
    "    # Add values on top of bars\n",
    "    for i, p in enumerate(ax_doc_count.patches):\n",
    "        ax_doc_count.annotate(f'{p.get_height():.0f}',\n",
    "                              (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                              ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.title('Number of Documents by Category')\n",
    "    plt.ylabel('Number of Documents')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # --- End Plot for Number of Documents ---\n",
    "\n",
    "    # Plot word count statistics\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.barplot(x='Category', y='Mean Word Count', data=word_count_df)\n",
    "\n",
    "    # Add values on top of bars\n",
    "    for i, p in enumerate(ax.patches):\n",
    "        ax.annotate(f'{p.get_height():.0f}',\n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.errorbar(\n",
    "        x=np.arange(len(word_count_df)),\n",
    "        y=word_count_df['Mean Word Count'],\n",
    "        yerr=word_count_df['Std Word Count'],\n",
    "        fmt='none', capsize=5, color='black'\n",
    "    )\n",
    "    plt.title('Mean Word Count by Category')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return category_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_stats = analyze_document_statistics(data, categories, unique_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clustering_confusion(true_labels, predicted_clusters, title='Confusion Matrix After Reassignment: Goldstandard vs Clustering Results'):\n",
    "\n",
    "    true_labels = label_encoder.fit_transform(categories)\n",
    "\n",
    "    # Analyze the matrix to suggest correspondences\n",
    "    correspondences = {}\n",
    "    unique_clusters = np.unique(predicted_clusters)\n",
    "    for cluster in unique_clusters:\n",
    "        # Find the true label with the maximum count for each cluster\n",
    "        cluster_indices = np.where(predicted_clusters == cluster)\n",
    "        true_labels_for_cluster = true_labels[cluster_indices]\n",
    "        if len(true_labels_for_cluster) > 0:\n",
    "            most_common_label = np.bincount(true_labels_for_cluster).argmax()\n",
    "            correspondences[cluster] = most_common_label\n",
    "    \n",
    "    # Reassign predicted clusters based on the correspondences\n",
    "    reassigned_clusters = [correspondences[cluster] for cluster in predicted_clusters]\n",
    "    \n",
    "    # Create confusion matrix after reassignment\n",
    "    cm_reassigned = confusion_matrix(true_labels, reassigned_clusters)\n",
    "    \n",
    "    # Create a heatmap of the confusion matrix after reassignment\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_reassigned, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[f'Cluster {i}' for i in unique_clusters],\n",
    "                yticklabels=np.unique(true_labels))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Clusters')\n",
    "    plt.ylabel('Goldstandard Labels')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate accuracy or other metrics\n",
    "    accuracy = accuracy_score(true_labels, reassigned_clusters)\n",
    "    print(f\"Accuracy after reassignment: {accuracy:.2f}\")\n",
    "    \n",
    "    return cm_reassigned, correspondences, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitional: K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(representations, n_clusters):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    predicted_clusters = kmeans.fit_predict(representations)\n",
    "    return predicted_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means clustering on each representation\n",
    "predicted_clusters_tf = perform_kmeans_clustering(tf_representations, n_clusters)\n",
    "predicted_clusters_tfidf = perform_kmeans_clustering(tfidf_representations, n_clusters)\n",
    "predicted_clusters_word2vec_avg = perform_kmeans_clustering(word2vec_avg_representations, n_clusters)\n",
    "predicted_clusters_word2vec_sum = perform_kmeans_clustering(word2vec_sum_representations, n_clusters)\n",
    "\n",
    "# Analyze clustering results and store the confusion matrices\n",
    "cm_tf, correspondences_tf, accuracy_tf = analyze_clustering_confusion(categories, predicted_clusters_tf)\n",
    "cm_tfidf, correspondences_tfidf, accuracy_tfidf = analyze_clustering_confusion(true_labels, predicted_clusters_tfidf)\n",
    "cm_word2vec_avg, correspondences_word2vec_avg, accuracy_word2vec_avg = analyze_clustering_confusion(true_labels, predicted_clusters_word2vec_avg)\n",
    "cm_word2vec_sum, correspondences_word2vec_sum, accuracy_word2vec_sum = analyze_clustering_confusion(true_labels, predicted_clusters_word2vec_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical: Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Agglomerative clustering on each representation\n",
    "agglomerative_clusters_tf = AgglomerativeClustering(n_clusters=n_clusters).fit_predict(tf_representations)\n",
    "agglomerative_clusters_tfidf = AgglomerativeClustering(n_clusters=n_clusters).fit_predict(tfidf_representations)\n",
    "agglomerative_clusters_word2vec_avg = AgglomerativeClustering(n_clusters=n_clusters).fit_predict(word2vec_avg_representations)\n",
    "agglomerative_clusters_word2vec_sum = AgglomerativeClustering(n_clusters=n_clusters).fit_predict(word2vec_sum_representations)\n",
    "\n",
    "# Analyze clustering results and store the confusion matrices\n",
    "cm_agglomerative_tf, correspondences_agglomerative_tf, accuracy_agglomerative_tf = analyze_clustering_confusion(categories, agglomerative_clusters_tf)\n",
    "cm_agglomerative_tfidf, correspondences_agglomerative_tfidf, accuracy_agglomerative_tfidf = analyze_clustering_confusion(true_labels, agglomerative_clusters_tfidf)\n",
    "cm_agglomerative_word2vec_avg, correspondences_agglomerative_word2vec_avg, accuracy_agglomerative_word2vec_avg = analyze_clustering_confusion(true_labels, agglomerative_clusters_word2vec_avg)\n",
    "cm_agglomerative_word2vec_sum, correspondences_agglomerative_word2vec_sum, accuracy_agglomerative_word2vec_sum = analyze_clustering_confusion(true_labels, agglomerative_clusters_word2vec_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density: DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBSCAN clustering on each representation\n",
    "dbscan_clusters_tf = DBSCAN().fit_predict(tf_representations)\n",
    "dbscan_clusters_tfidf = DBSCAN().fit_predict(tfidf_representations)\n",
    "dbscan_clusters_word2vec_avg = DBSCAN().fit_predict(word2vec_avg_representations)\n",
    "dbscan_clusters_word2vec_sum = DBSCAN().fit_predict(word2vec_sum_representations)\n",
    "\n",
    "# Analyze clustering results and store the confusion matrices\n",
    "cm_dbscan_tf, correspondences_dbscan_tf, accuracy_dbscan_tf = analyze_clustering_confusion(categories, dbscan_clusters_tf)\n",
    "cm_dbscan_tfidf, correspondences_dbscan_tfidf, accuracy_dbscan_tfidf = analyze_clustering_confusion(true_labels, dbscan_clusters_tfidf)\n",
    "cm_dbscan_word2vec_avg, correspondences_dbscan_word2vec_avg, accuracy_dbscan_word2vec_avg = analyze_clustering_confusion(true_labels, dbscan_clusters_word2vec_avg)\n",
    "cm_dbscan_word2vec_sum, correspondences_dbscan_word2vec_sum, accuracy_dbscan_word2vec_sum = analyze_clustering_confusion(true_labels, dbscan_clusters_word2vec_sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## Internal validation\n",
    "### Silhouette score\n",
    "### Calinski-Harabasz index\n",
    "### Davies-Bouldin index\n",
    "## External validation\n",
    "### Confusion matrix\n",
    "### Classification report\n",
    "### Adjusted Rand index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
