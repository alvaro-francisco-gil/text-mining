{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import gensim.downloader as api\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = '/text-mining/data/02_text_representation/Corpus-representacion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files_to_dict(folder_path):\n",
    "    files_dict = {}\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                    files_dict[file_path] = f.read()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not read file {file_path}: {e}\")\n",
    "    return files_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = save_files_to_dict(data_folder_path)\n",
    "data = list(data_dict.values())\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xref: cantaloupe.srv.cs.cmu.edu sci.physics:50976 sci.electronics:53128\n",
      "Newsgroups: sci.physics,sci.electronics\n",
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usenet.ins.cwru.edu!magnus.acs.ohio-state.edu!csn!teal.csn.org!et\n",
      "From: et@teal.csn.org (Eric H. Taylor)\n",
      "Subject: Holes: practical questions, was - Philosophical Question\n",
      "Message-ID: <C584xJ.3nq@csn.org>\n",
      "Followup-To: sci.physics\n",
      "Summary: How do we preferentially amplify holes instead of electrons?\n",
      "Keywords: holes electrons semi-conductors mobility\n",
      "Sender: Eric H. Taylor\n",
      "Nntp-Posting-Host: teal.csn.org\n",
      "Organization: 4-L Laboratories\n",
      "References: <31MAR199309335376@csa1.lbl.gov> <1993Mar31.194457.18742@watson.ibm.com> <12426@sun13.scri.fsu.edu>\n",
      "Date: Fri, 9 Apr 1993 16:10:31 GMT\n",
      "Expires: Sun, 9 May 1993 06:00:00 GMT\n",
      "Lines: 48\n",
      "\n",
      "In article <12426@sun13.scri.fsu.edu> jac@ds8.scri.fsu.edu (Jim Carr) writes:\n",
      ">[...]\n",
      ">I agree.  I come at this from nuclear physics, where one often discusses \n",
      ">particle-hole excitations and certain reactions have the effect of \n",
      ">applying an annihilation operator and creating a hole, and it is a \n",
      ">subtle question.  The longer one works with them, the more real they \n",
      ">become.  There are also quasi-particles, which raise the same sort \n",
      ">of question about how \"real\" the entity is.  The phenomenon is most \n",
      ">certainly a real one. \n",
      "\n",
      "OK, I've asked this before, and with a new thread on these lines, I\n",
      "ask this again:\n",
      "\n",
      "1: If a large hole current is run thru a resistor, will there be\n",
      "   I^2 * R cooling instead of heating?\n",
      "\n",
      "2: Can anyone design an amplifier that preferentially amplifies\n",
      "   hole currents over normal electron currents?\n",
      "\n",
      "3: what semiconductor materials have the highest ratio of\n",
      "   hole mobility to electron mobility? (please quote actual\n",
      "   test samples rather than estimates based on theory. Also,\n",
      "   don't be limited to semiconductors: consider also insulators,\n",
      "   resistors, dielectrics, piezo-electrics, conductors,\n",
      "   magnets (metal, ceramic), magnetostrictives, etc).\n",
      "\n",
      "NOTES:\n",
      "\n",
      "   to summarize, this thread has so far stated that the only area\n",
      "   where holes are not detectable is the vacuum. That is, hole\n",
      "   particles only exist in the presence of matter.\n",
      "   Previous threads have stated that holes only exist in certain\n",
      "   semi-conductors. The question that naturally arises is if\n",
      "   the hole currents inside a semi-conductor vanish at the point\n",
      "   where the semiconductor is joined to a conductor (say, copper).\n",
      "   I don't want a theoretical discussion here about whether\n",
      "   holes could exist inside metal conductors, rather I ask for\n",
      "   an experimental discussion on how to amplify and detect such\n",
      "   currents *if* they exist.\n",
      "   Also note that I have cross-posted this to sci.electronics\n",
      "   since this is now becoming an electronic discussion.\n",
      "\n",
      "Thanx,\n",
      "Eric.\n",
      "\n",
      "----\n",
      " ET   \"A Force of Nature\"\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_index = 527\n",
    "print(data[example_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_message_body(email_text):\n",
    "    \"\"\"\n",
    "    Extracts the main message body from an email by removing headers, unnecessary metadata, \n",
    "    and signatures, while preserving quoted lines that provide meaningful context.\n",
    "    \"\"\"\n",
    "    # Split the email into lines\n",
    "    lines = email_text.splitlines()\n",
    "\n",
    "    # Remove header (everything before the first blank line)\n",
    "    blank_line_index = next((i for i, line in enumerate(lines) if line.strip() == \"\"), None)\n",
    "    if blank_line_index is not None:\n",
    "        lines = lines[blank_line_index + 1:]\n",
    "\n",
    "    # Remove lines containing email addresses\n",
    "    email_pattern = re.compile(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\")\n",
    "    lines = [line for line in lines if not email_pattern.search(line)]\n",
    "\n",
    "    # Remove lines with only one to three capitalized words\n",
    "    capitalized_words_pattern = re.compile(r\"^([A-Z][a-z]+\\s?){1,3}$\")\n",
    "    lines = [line for line in lines if not capitalized_words_pattern.match(line.strip())]\n",
    "\n",
    "    # Remove lines after signature patterns\n",
    "    signature_patterns = [\n",
    "        r\"^--\\s*$\",  # Standard signature delimiter\n",
    "        r\"^>--\",     # Quoted signature delimiter\n",
    "        r\"^Kind regards\",  # Common closing phrases\n",
    "        r\"^Best regards\",\n",
    "        r\"^Sincerely\",\n",
    "        r\"^Sent from my iPhone\",\n",
    "        r\"^Sent from my BlackBerry\",\n",
    "        r\"^Confidentiality Notice\",  # Legal disclaimers\n",
    "    ]\n",
    "\n",
    "    filtered_lines = []\n",
    "    skip_lines = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Check for signature patterns\n",
    "        if any(re.match(pattern, line.strip(), re.IGNORECASE) for pattern in signature_patterns):\n",
    "            skip_lines = True\n",
    "        # Stop skipping after a blank line\n",
    "        if skip_lines and line.strip() == \"\":\n",
    "            skip_lines = False\n",
    "            continue\n",
    "        # Skip lines if in the skip mode\n",
    "        if skip_lines:\n",
    "            continue\n",
    "\n",
    "        filtered_lines.append(line)\n",
    "\n",
    "    # Retain quoted lines unless they are irrelevant or part of a signature\n",
    "    meaningful_quoted_lines = []\n",
    "    for line in filtered_lines:\n",
    "        if line.strip().startswith(\">\"):\n",
    "            # Keep the line if itâ€™s not part of a quoted signature or irrelevant\n",
    "            if not re.match(r\"^>--\", line.strip()):\n",
    "                meaningful_quoted_lines.append(line)\n",
    "        else:\n",
    "            meaningful_quoted_lines.append(line)\n",
    "\n",
    "    # Join remaining lines to form the message body\n",
    "    message_body = \"\\n\".join(meaningful_quoted_lines).strip()\n",
    "    return message_body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">[...]\n",
      ">I agree.  I come at this from nuclear physics, where one often discusses \n",
      ">particle-hole excitations and certain reactions have the effect of \n",
      ">applying an annihilation operator and creating a hole, and it is a \n",
      ">subtle question.  The longer one works with them, the more real they \n",
      ">become.  There are also quasi-particles, which raise the same sort \n",
      ">of question about how \"real\" the entity is.  The phenomenon is most \n",
      ">certainly a real one. \n",
      "\n",
      "OK, I've asked this before, and with a new thread on these lines, I\n",
      "ask this again:\n",
      "\n",
      "1: If a large hole current is run thru a resistor, will there be\n",
      "   I^2 * R cooling instead of heating?\n",
      "\n",
      "2: Can anyone design an amplifier that preferentially amplifies\n",
      "   hole currents over normal electron currents?\n",
      "\n",
      "3: what semiconductor materials have the highest ratio of\n",
      "   hole mobility to electron mobility? (please quote actual\n",
      "   test samples rather than estimates based on theory. Also,\n",
      "   don't be limited to semiconductors: consider also insulators,\n",
      "   resistors, dielectrics, piezo-electrics, conductors,\n",
      "   magnets (metal, ceramic), magnetostrictives, etc).\n",
      "\n",
      "NOTES:\n",
      "\n",
      "   to summarize, this thread has so far stated that the only area\n",
      "   where holes are not detectable is the vacuum. That is, hole\n",
      "   particles only exist in the presence of matter.\n",
      "   Previous threads have stated that holes only exist in certain\n",
      "   semi-conductors. The question that naturally arises is if\n",
      "   the hole currents inside a semi-conductor vanish at the point\n",
      "   where the semiconductor is joined to a conductor (say, copper).\n",
      "   I don't want a theoretical discussion here about whether\n",
      "   holes could exist inside metal conductors, rather I ask for\n",
      "   an experimental discussion on how to amplify and detect such\n",
      "   currents *if* they exist.\n",
      "   Also note that I have cross-posted this to sci.electronics\n",
      "   since this is now becoming an electronic discussion.\n",
      "\n",
      "Thanx,\n",
      "Eric.\n",
      "\n",
      "----\n",
      " ET   \"A Force of Nature\"\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data = [extract_message_body(email) for email in data]\n",
    "print(data[example_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_numbers=True, word_reduction=\"none\"):\n",
    "    \"\"\"\n",
    "    Preprocesses text by removing punctuation, numbers, stop-words,\n",
    "    and optionally applying lemmatization or stemming.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        remove_numbers (bool): Whether to remove numbers from the text.\n",
    "        word_reduction (str): Type of word reduction to apply. Options are:\n",
    "            \"lemmatization\", \"stemming\", or \"none\".\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "    \"\"\"\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Remove numbers if required\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop-words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Apply word reduction if specified\n",
    "    if word_reduction == \"lemmatization\":\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    elif word_reduction == \"stemming\":\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "    # If word_reduction is \"none\" or invalid, no reduction is applied\n",
    "    \n",
    "    # Join words back into a single string\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agre come nuclear physic one often discuss particlehol excit certain reaction effect appli annihil oper creat hole subtl question longer one work real becom also quasiparticl rais sort question real entiti phenomenon certainli real one ok ive ask new thread line ask larg hole current run thru resistor r cool instead heat anyon design amplifi preferenti amplifi hole current normal electron current semiconductor materi highest ratio hole mobil electron mobil pleas quot actual test sampl rather estim base theori also dont limit semiconductor consid also insul resistor dielectr piezoelectr conductor magnet metal ceram magnetostrict etc note summar thread far state area hole detect vacuum hole particl exist presenc matter previou thread state hole exist certain semiconductor question natur aris hole current insid semiconductor vanish point semiconductor join conductor say copper dont want theoret discuss whether hole could exist insid metal conductor rather ask experiment discuss amplifi detect current exist also note crosspost scielectron sinc becom electron discuss thanx eric et forc natur\n"
     ]
    }
   ],
   "source": [
    "processed_data = [preprocess_text(email) for email in data]\n",
    "stemmed_data = [preprocess_text(email, word_reduction=\"stemming\") for email in data]\n",
    "print(stemmed_data[example_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_vectors(doc, model):\n",
    "    \"\"\"\n",
    "    Convert a document to vectors (average and sum) based on its word embeddings.\n",
    "    \n",
    "    Args:\n",
    "        doc (str): Preprocessed document.\n",
    "        model (gensim model): Pre-trained word embeddings model.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_vector, sum_vector)\n",
    "    \"\"\"\n",
    "    words = doc.split()\n",
    "    word_vectors = [model[word] for word in words if word in model]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(model.vector_size), np.zeros(model.vector_size)\n",
    "    word_vectors = np.array(word_vectors)\n",
    "    return np.mean(word_vectors, axis=0), np.sum(word_vectors, axis=0)\n",
    "\n",
    "def compute_text_representations(documents, method=\"tfidf\"):\n",
    "    \"\"\"\n",
    "    Compute text representations using the specified method.\n",
    "    \n",
    "    Args:\n",
    "        documents (list of str): List of raw text documents.\n",
    "        method (str): Representation method to use. Options are:\n",
    "            \"tf\" - Term Frequency\n",
    "            \"tfidf\" - Term Frequency-Inverse Document Frequency\n",
    "            \"word2vec_avg\" - Word2Vec average embeddings\n",
    "            \"word2vec_sum\" - Word2Vec sum embeddings\n",
    "    \n",
    "    Returns:\n",
    "        array-like: The computed text representation matrix\n",
    "    \"\"\"\n",
    "    # Preprocess documents\n",
    "    preprocessed_docs = [preprocess_text(doc) for doc in documents]\n",
    "    \n",
    "    if method == \"tf\":\n",
    "        vectorizer = TfidfVectorizer(use_idf=False, norm=None)\n",
    "        return vectorizer.fit_transform(preprocessed_docs)\n",
    "        \n",
    "    elif method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        return vectorizer.fit_transform(preprocessed_docs)\n",
    "        \n",
    "    elif method == \"word2vec_avg\":\n",
    "        vectors = []\n",
    "        for doc in preprocessed_docs:\n",
    "            avg_vector, _ = document_to_vectors(doc, word2vec_model)\n",
    "            vectors.append(avg_vector)\n",
    "        return np.array(vectors)\n",
    "        \n",
    "    elif method == \"word2vec_sum\":\n",
    "        vectors = []\n",
    "        for doc in preprocessed_docs:\n",
    "            _, sum_vector = document_to_vectors(doc, word2vec_model)\n",
    "            vectors.append(sum_vector)\n",
    "        return np.array(vectors)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Valid options are: 'tf', 'tfidf', 'word2vec_avg', 'word2vec_sum'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_representations = compute_text_representations(stemmed_data, method=\"tf\")\n",
    "tfidf_representations = compute_text_representations(stemmed_data, method=\"tfidf\")\n",
    "word2vec_avg_representations = compute_text_representations(processed_data, method=\"word2vec_avg\")\n",
    "word2vec_sum_representations = compute_text_representations(processed_data, method=\"word2vec_sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"02_text_representations_tf.npy\", tf_representations.toarray())\n",
    "np.save(\"02_text_representations_tfidf.npy\", tfidf_representations.toarray())\n",
    "np.save(\"02_text_representations_word2vec_avg.npy\", word2vec_avg_representations)\n",
    "np.save(\"02_text_representations_word2vec_sum.npy\", word2vec_sum_representations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
